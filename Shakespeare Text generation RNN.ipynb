{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93df5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe269929",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b531839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0aa542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9ca266",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c8d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9a5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185537b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-5d518b9a969b>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  len(characters)), dtype=np.bool)\n",
      "<ipython-input-8-5d518b9a969b>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  len(characters)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=np.bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbbf106",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88fae12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "651/651 [==============================] - 173s 247ms/step - loss: 2.1683\n",
      "Epoch 2/20\n",
      "651/651 [==============================] - 182s 279ms/step - loss: 1.7320\n",
      "Epoch 3/20\n",
      "651/651 [==============================] - 217s 333ms/step - loss: 1.6024\n",
      "Epoch 4/20\n",
      "651/651 [==============================] - 182s 279ms/step - loss: 1.5331\n",
      "Epoch 5/20\n",
      "651/651 [==============================] - 189s 290ms/step - loss: 1.4847\n",
      "Epoch 6/20\n",
      "651/651 [==============================] - 142s 218ms/step - loss: 1.4494\n",
      "Epoch 7/20\n",
      "651/651 [==============================] - 110s 170ms/step - loss: 1.4209\n",
      "Epoch 8/20\n",
      "651/651 [==============================] - 110s 169ms/step - loss: 1.3976\n",
      "Epoch 9/20\n",
      "651/651 [==============================] - 113s 173ms/step - loss: 1.3780\n",
      "Epoch 10/20\n",
      "651/651 [==============================] - 111s 170ms/step - loss: 1.3634\n",
      "Epoch 11/20\n",
      "651/651 [==============================] - 111s 171ms/step - loss: 1.3492\n",
      "Epoch 12/20\n",
      "651/651 [==============================] - 111s 171ms/step - loss: 1.3357\n",
      "Epoch 13/20\n",
      "651/651 [==============================] - 112s 173ms/step - loss: 1.3262\n",
      "Epoch 14/20\n",
      "651/651 [==============================] - 111s 171ms/step - loss: 1.3152\n",
      "Epoch 15/20\n",
      "651/651 [==============================] - 113s 173ms/step - loss: 1.3088\n",
      "Epoch 16/20\n",
      "651/651 [==============================] - 112s 172ms/step - loss: 1.3002\n",
      "Epoch 17/20\n",
      "651/651 [==============================] - 115s 177ms/step - loss: 1.2924\n",
      "Epoch 18/20\n",
      "651/651 [==============================] - 112s 172ms/step - loss: 1.2871\n",
      "Epoch 19/20\n",
      "651/651 [==============================] - 112s 172ms/step - loss: 1.2801\n",
      "Epoch 20/20\n",
      "651/651 [==============================] - 113s 174ms/step - loss: 1.2744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc5f3cf940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d44b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abe292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d0c50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et me have\n",
      "a dram of poison, such soon-sleast of the ways\n",
      "should stay the countract the complio;\n",
      "and the truth, that is the straight is the charrents of the bloody\n",
      "of the charrom of the charrents the countract\n",
      "the truth and the charrents the bark of the charrents\n",
      "the constines of the brother the breath the contrall\n",
      "and the complio the str\n",
      "name in england;\n",
      "and i must find that time is not the court.\n",
      "\n",
      "mercutio:\n",
      "good my be repart the servand of the cast\n",
      "a mortal tonguess the world is the bark.\n",
      "\n",
      "king richard ii:\n",
      "and be thy speak of the charrents of their heads,\n",
      "and i have spent to be a princh and the foul death,\n",
      "and this thou slain thy hand of england,\n",
      "she chaige his part the \n",
      "request, to stand aside,\n",
      "while i use furch the brother and all the streas.\n",
      "\n",
      "post:\n",
      "ay, i have ster the crown of this will be this kins\n",
      "and be abless of this is sunserfecty here.\n",
      "\n",
      "romeo:\n",
      "and thou hast the be not to my son and they see\n",
      "the crowner therefore and the world and will\n",
      "to sing of the strength hours hence be more.\n",
      "\n",
      "king richard iv:\n",
      " is my unrest.\n",
      "\n",
      "capulet:\n",
      "nay, gentlemen, where, and therefore do it thee.\n",
      "\n",
      "king richard ii:\n",
      "anchou, let's romeo with the clarge and the balmed will be\n",
      "than have not so thank and grant it is speak,\n",
      "and repover'd at friend and for the brother,\n",
      "or stand them to the encomvond in our state,\n",
      "the truth, how i did in the love and thy man,\n",
      "more th\n",
      "ks yet she says nothing: what of that?\n",
      "have speak of no moran: neither, the romeo?\n",
      "seem'd her man or many here's here, and have\n",
      "a swearn by the bright them i will it the tremend\n",
      "and thy love with these have men not to save;\n",
      "mard your head of the way we straight.\n",
      "\n",
      "first mester:\n",
      "and then, but that would look with thy salister.\n",
      "\n",
      "warwick:\n",
      "i a\n",
      "eyman to grief?\n",
      "\n",
      "john of gaunt:\n",
      "all place toe you love to have setted it\n",
      "love: then be subjects case this man: though a tear\n",
      "the great the mind then king may proport\n",
      "un our thing in ye wood of my head,\n",
      "and thou see his father, be too subject.\n",
      "shall our ewford's king and thou drew forth send\n",
      "the goar awe senoiss for since course how that h\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
